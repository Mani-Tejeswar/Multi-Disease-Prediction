{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huqk0BxkTS0v",
        "outputId": "f9af699c-5981-4e00-cf9e-28983bf5378f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "First 5 rows of the dataset:\n",
            "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
            "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
            "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
            "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
            "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
            "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
            "\n",
            "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
            "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
            "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
            "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
            "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
            "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
            "\n",
            "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
            "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
            "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
            "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
            "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
            "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
            "\n",
            "    spread2        D2       PPE  \n",
            "0  0.266482  2.301442  0.284654  \n",
            "1  0.335590  2.486855  0.368674  \n",
            "2  0.311173  2.342259  0.332634  \n",
            "3  0.334147  2.405554  0.368975  \n",
            "4  0.234513  2.332180  0.410335  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "\n",
            "Dataset information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 195 entries, 0 to 194\n",
            "Data columns (total 24 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   name              195 non-null    object \n",
            " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
            " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
            " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
            " 4   MDVP:Jitter(%)    195 non-null    float64\n",
            " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
            " 6   MDVP:RAP          195 non-null    float64\n",
            " 7   MDVP:PPQ          195 non-null    float64\n",
            " 8   Jitter:DDP        195 non-null    float64\n",
            " 9   MDVP:Shimmer      195 non-null    float64\n",
            " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
            " 11  Shimmer:APQ3      195 non-null    float64\n",
            " 12  Shimmer:APQ5      195 non-null    float64\n",
            " 13  MDVP:APQ          195 non-null    float64\n",
            " 14  Shimmer:DDA       195 non-null    float64\n",
            " 15  NHR               195 non-null    float64\n",
            " 16  HNR               195 non-null    float64\n",
            " 17  status            195 non-null    int64  \n",
            " 18  RPDE              195 non-null    float64\n",
            " 19  DFA               195 non-null    float64\n",
            " 20  spread1           195 non-null    float64\n",
            " 21  spread2           195 non-null    float64\n",
            " 22  D2                195 non-null    float64\n",
            " 23  PPE               195 non-null    float64\n",
            "dtypes: float64(22), int64(1), object(1)\n",
            "memory usage: 36.7+ KB\n",
            "\n",
            "Applying preprocessing steps to training data...\n",
            "Outliers capped for all features.\n",
            "\n",
            "First 5 rows of scaled features (after outlier treatment):\n",
            "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
            "0    -0.829300     -0.500094     -0.964110        0.701875          1.017692   \n",
            "1    -0.770972     -0.638805     -0.050885        1.308591          1.382624   \n",
            "2    -0.909476     -0.919993     -0.104142        1.578975          1.747556   \n",
            "3    -0.909622     -0.811616     -0.108588        1.404215          1.747556   \n",
            "4    -0.925657     -0.748930     -0.125313        2.350560          2.477420   \n",
            "\n",
            "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
            "0  0.440015  1.437914    0.438206      0.885615          0.976347  ...   \n",
            "1  0.999991  2.285930    0.998426      1.943849          2.235504  ...   \n",
            "2  1.465655  2.368044    1.468224      1.402105          1.328911  ...   \n",
            "3  1.218086  2.297874    1.216617      1.557834          1.549263  ...   \n",
            "4  2.119942  2.368044    2.122797      2.118818          1.971081  ...   \n",
            "\n",
            "   MDVP:APQ  Shimmer:DDA       NHR       HNR      RPDE       DFA   spread1  \\\n",
            "0  0.518684     0.710297  0.236191 -0.201203 -0.807838  1.760814  0.810831   \n",
            "1  1.594294     1.755272  0.063834 -0.648894 -0.387524  1.837562  1.494886   \n",
            "2  0.995279     1.341012 -0.315105 -0.288994 -0.662075  1.942048  1.153723   \n",
            "3  1.135408     1.524193 -0.288212 -0.290603 -0.613134  1.832380  1.455661   \n",
            "4  1.668978     2.145401 -0.035179 -0.519275 -0.783021  1.909364  1.798426   \n",
            "\n",
            "    spread2        D2       PPE  \n",
            "0  0.482584 -0.209449  0.906632  \n",
            "1  1.316596  0.280817  1.870326  \n",
            "2  1.021926 -0.101522  1.456953  \n",
            "3  1.299181  0.065842  1.873778  \n",
            "4  0.096775 -0.128172  2.348170  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "\n",
            "Original Training set size: 156 samples\n",
            "Original Testing set size: 39 samples\n",
            "Original Outcome distribution in training set:\n",
            "status\n",
            "1    0.75641\n",
            "0    0.24359\n",
            "Name: proportion, dtype: float64\n",
            "Original Outcome distribution in testing set:\n",
            "status\n",
            "1    0.74359\n",
            "0    0.25641\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Applying SMOTE to balance the training data...\n",
            "\n",
            "Resampled Training set size: 236 samples\n",
            "Resampled Outcome distribution in training set:\n",
            "status\n",
            "0    0.5\n",
            "1    0.5\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Starting Enhanced Hyperparameter Tuning for SVM on resampled data (this might take a moment)...\n",
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "\n",
            "Best parameters found: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Best cross-validation F1-weighted score on resampled data: 0.9746\n",
            "\n",
            "Best SVM model trained successfully using best parameters on resampled data.\n",
            "\n",
            "Model Accuracy on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment): 0.9744\n",
            "\n",
            "Classification Report on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95        10\n",
            "           1       1.00      0.97      0.98        29\n",
            "\n",
            "    accuracy                           0.97        39\n",
            "   macro avg       0.95      0.98      0.97        39\n",
            "weighted avg       0.98      0.97      0.97        39\n",
            "\n",
            "\n",
            "Confusion Matrix on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment):\n",
            "[[10  0]\n",
            " [ 1 28]]\n",
            "\n",
            "Model saved to parkinsons_svm_model.joblib\n",
            "Scaler saved to parkinsons_scaler.joblib\n",
            "Training IQR bounds for outlier treatment saved to parkinsons_train_iqr_bounds.joblib\n",
            "\n",
            "--- Example: Loading saved model and predicting on new data ---\n",
            "Model, scaler, and IQR bounds loaded successfully.\n",
            "\n",
            "New patient data for prediction:\n",
            "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
            "0      119.992       157.302        74.997         0.00784           0.00007   \n",
            "\n",
            "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  \\\n",
            "0    0.0037   0.00494     0.01109       0.04374             0.426   \n",
            "\n",
            "   Shimmer:APQ3  Shimmer:APQ5  MDVP:APQ  Shimmer:DDA      DFA   spread1  \\\n",
            "0       0.02182        0.0313   0.02971      0.06545  0.73789 -5.454504   \n",
            "\n",
            "    spread2   D2  PPE  \n",
            "0  0.282866  2.0  0.1  \n",
            "\n",
            "Predicted Outcome for new patient: Parkinsons Disease\n",
            "Prediction Probability (No Parkinsons Disease, Parkinsons Disease): [0.06997136 0.93002864]\n",
            "\n",
            "New patient data 2 for prediction:\n",
            "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
            "0        150.0         200.0         100.0           0.003           0.00002   \n",
            "\n",
            "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  \\\n",
            "0    0.0015     0.002      0.0045         0.015              0.15   \n",
            "\n",
            "   Shimmer:APQ3  Shimmer:APQ5  MDVP:APQ  Shimmer:DDA  DFA  spread1  spread2  \\\n",
            "0         0.007         0.009     0.008        0.021  0.7     -4.0      0.2   \n",
            "\n",
            "    D2   PPE  \n",
            "0  1.8  0.05  \n",
            "\n",
            "Predicted Outcome for new patient 2: Parkinsons Disease\n",
            "Prediction Probability (No Parkinsons Disease, Parkinsons Disease): [0.05367414 0.94632586]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE # Import SMOTE\n",
        "import joblib # For saving and loading models\n",
        "import os # Import os module to set environment variables\n",
        "\n",
        "# --- Set environment variables to mitigate threading issues ---\n",
        "# This often resolves 'NoneType' object has no attribute 'split' errors\n",
        "# by forcing single-threaded operation for underlying numerical libraries.\n",
        "os.environ['OMP_NUM_THREADS'] = '1'\n",
        "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
        "# You can also try setting MKL_NUM_THREADS if you suspect MKL is involved\n",
        "# os.environ['MKL_NUM_THREADS'] = '1'\n",
        "\n",
        "# --- 1. Load the dataset ---\n",
        "# The dataset 'parkinsons.csv' is assumed to be available in the environment.\n",
        "try:\n",
        "    df = pd.read_csv('/content/parkinsons.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "    print(\"First 5 rows of the dataset:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nDataset information:\")\n",
        "    df.info()\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'parkinsons.csv' not found. Please ensure the file is uploaded correctly.\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Data Preprocessing ---\n",
        "\n",
        "# Identify features (X) and target (y)\n",
        "# For parkinsons.csv, 'status' is typically the target variable (1 for Parkinson's, 0 for healthy)\n",
        "# All other columns are features. The 'name' column is usually an identifier and should be dropped.\n",
        "X = df.drop(['status', 'name'], axis=1) # Assuming 'status' is the outcome column and 'name' is an identifier\n",
        "y = df['status']\n",
        "\n",
        "# Note: The Parkinson's dataset typically does not have 0s representing missing values\n",
        "# in critical columns that need imputation like the diabetes dataset.\n",
        "# If your 'parkinsons.csv' has specific missing values (e.g., NaN), you would need to add\n",
        "# appropriate handling here (e.g., df.fillna(df.mean()), or more advanced imputation).\n",
        "\n",
        "# Function to apply preprocessing steps (outlier treatment, scaling)\n",
        "# This function will be used for both training and new data prediction\n",
        "def preprocess_data(data_df, scaler=None, is_training=True, train_iqr_bounds=None):\n",
        "    processed_df = data_df.copy()\n",
        "\n",
        "    # Outlier Treatment (Capping using IQR method)\n",
        "    # For new data, use IQR bounds calculated from training data\n",
        "    current_iqr_bounds = {}\n",
        "    if is_training:\n",
        "        for column in processed_df.columns:\n",
        "            Q1 = processed_df[column].quantile(0.25)\n",
        "            Q3 = processed_df[column].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            processed_df[column] = processed_df[column].clip(lower=lower_bound, upper=upper_bound)\n",
        "            current_iqr_bounds[column] = {'lower': lower_bound, 'upper': upper_bound}\n",
        "    else:\n",
        "        if train_iqr_bounds is None:\n",
        "            raise ValueError(\"train_iqr_bounds must be provided for new data preprocessing.\")\n",
        "        for column in processed_df.columns:\n",
        "            lower_bound = train_iqr_bounds[column]['lower']\n",
        "            upper_bound = train_iqr_bounds[column]['upper']\n",
        "            processed_df[column] = processed_df[column].clip(lower=lower_bound, upper=upper_bound)\n",
        "        current_iqr_bounds = train_iqr_bounds # No need to recalculate for new data\n",
        "\n",
        "    # Feature Scaling\n",
        "    if is_training:\n",
        "        scaler = StandardScaler()\n",
        "        scaled_data = scaler.fit_transform(processed_df)\n",
        "    else:\n",
        "        if scaler is None:\n",
        "            raise ValueError(\"Scaler must be provided for new data preprocessing.\")\n",
        "        scaled_data = scaler.transform(processed_df)\n",
        "\n",
        "    processed_df_scaled = pd.DataFrame(scaled_data, columns=processed_df.columns)\n",
        "\n",
        "    if is_training:\n",
        "        return processed_df_scaled, scaler, current_iqr_bounds\n",
        "    else:\n",
        "        return processed_df_scaled\n",
        "\n",
        "\n",
        "# Preprocess training data\n",
        "print(\"\\nApplying preprocessing steps to training data...\")\n",
        "X_processed, scaler, train_iqr_bounds = preprocess_data(X, is_training=True)\n",
        "\n",
        "print(\"Outliers capped for all features.\")\n",
        "\n",
        "print(\"\\nFirst 5 rows of scaled features (after outlier treatment):\")\n",
        "print(X_processed.head())\n",
        "\n",
        "# --- 3. Split the data into training and testing sets ---\n",
        "# We'll use 80% for training and 20% for testing.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nOriginal Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Original Testing set size: {X_test.shape[0]} samples\")\n",
        "print(f\"Original Outcome distribution in training set:\\n{y_train.value_counts(normalize=True)}\")\n",
        "print(f\"Original Outcome distribution in testing set:\\n{y_test.value_counts(normalize=True)}\")\n",
        "\n",
        "# --- 4. Apply SMOTE to the training data ---\n",
        "print(\"\\nApplying SMOTE to balance the training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "# The environment variables set at the top should handle threading,\n",
        "# so the explicit threadpool_limits context manager is less critical here but can remain.\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"\\nResampled Training set size: {X_train_resampled.shape[0]} samples\")\n",
        "print(f\"Resampled Outcome distribution in training set:\\n{y_train_resampled.value_counts(normalize=True)}\")\n",
        "\n",
        "\n",
        "# --- 5. Train an SVM Classifier with Enhanced Hyperparameter Tuning on Resampled Data ---\n",
        "print(\"\\nStarting Enhanced Hyperparameter Tuning for SVM on resampled data (this might take a moment)...\")\n",
        "\n",
        "# Define an expanded parameter grid to search\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100, 1000],          # Regularization parameter: expanded range\n",
        "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],      # Kernel coefficient for 'rbf'\n",
        "    'kernel': ['rbf']                            # Focusing on RBF kernel\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "# Set probability=True to enable predict_proba\n",
        "# n_jobs=1 is kept to ensure single-threaded operation for GridSearchCV itself\n",
        "grid_search = GridSearchCV(\n",
        "    SVC(random_state=42, class_weight='balanced', probability=True),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='f1_weighted',\n",
        "    n_jobs=1, # Explicitly set to 1\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV to the RESAMPLED training data\n",
        "# The environment variables should handle underlying BLAS/LAPACK threading\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation F1-weighted score on resampled data: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Get the best estimator (the SVM model with the best parameters)\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "print(\"\\nBest SVM model trained successfully using best parameters on resampled data.\")\n",
        "\n",
        "# --- 6. Evaluate the best model's performance on the ORIGINAL Test Set ---\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred = best_svm_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment): {accuracy:.4f}\")\n",
        "\n",
        "# Generate a classification report (precision, recall, f1-score)\n",
        "print(\"\\nClassification Report on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment):\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Generate a confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment):\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Interpretation of Confusion Matrix:\n",
        "# [[True Negatives (TN)  False Positives (FP)]\n",
        "#  [False Negatives (FN) True Positives (TP)]]\n",
        "# For Parkinson's disease prediction:\n",
        "# TN: Correctly predicted no Parkinson's disease\n",
        "# FP: Incorrectly predicted Parkinson's disease (Type I error)\n",
        "# FN: Incorrectly predicted no Parkinson's disease (Type II error, more critical in medical diagnosis)\n",
        "# TP: Correctly predicted Parkinson's disease\n",
        "\n",
        "# --- 7. Save the trained model and preprocessing objects ---\n",
        "model_filename = 'parkinsons_svm_model.joblib'\n",
        "scaler_filename = 'parkinsons_scaler.joblib'\n",
        "train_iqr_bounds_filename = 'parkinsons_train_iqr_bounds.joblib'\n",
        "\n",
        "joblib.dump(best_svm_model, model_filename)\n",
        "joblib.dump(scaler, scaler_filename)\n",
        "joblib.dump(train_iqr_bounds, train_iqr_bounds_filename)\n",
        "\n",
        "print(f\"\\nModel saved to {model_filename}\")\n",
        "print(f\"Scaler saved to {scaler_filename}\")\n",
        "print(f\"Training IQR bounds for outlier treatment saved to {train_iqr_bounds_filename}\")\n",
        "\n",
        "\n",
        "# --- 8. Example: Load model and predict on new data ---\n",
        "print(\"\\n--- Example: Loading saved model and predicting on new data ---\")\n",
        "\n",
        "# Load the saved model, scaler, and IQR bounds\n",
        "loaded_model = joblib.load(model_filename)\n",
        "loaded_scaler = joblib.load(scaler_filename)\n",
        "loaded_train_iqr_bounds = joblib.load(train_iqr_bounds_filename)\n",
        "\n",
        "print(\"Model, scaler, and IQR bounds loaded successfully.\")\n",
        "\n",
        "# Create some hypothetical new data for prediction\n",
        "# Ensure the new data has the same columns as the training data, in the same order\n",
        "# Common columns in parkinsons.csv: MDVP:Fo(Hz), MDVP:Fhi(Hz), MDVP:Flo(Hz), MDVP:Jitter(%),\n",
        "# MDVP:Jitter(Abs), MDVP:RAP, MDVP:PPQ, Jitter:RAP, MDVP:Shimmer, MDVP:Shimmer(dB),\n",
        "# Shimmer:APQ3, Shimmer:APQ5, MDVP:APQ, Shimmer:DD, DFA, spread1, spread2, D2, PPE\n",
        "new_patient_data = pd.DataFrame({\n",
        "    'MDVP:Fo(Hz)': [119.992], 'MDVP:Fhi(Hz)': [157.302], 'MDVP:Flo(Hz)': [74.997],\n",
        "    'MDVP:Jitter(%)': [0.00784], 'MDVP:Jitter(Abs)': [0.00007], 'MDVP:RAP': [0.00370],\n",
        "    'MDVP:PPQ': [0.00494], 'Jitter:DDP': [0.01109], 'MDVP:Shimmer': [0.04374],\n",
        "    'MDVP:Shimmer(dB)': [0.426], 'Shimmer:APQ3': [0.02182], 'Shimmer:APQ5': [0.03130],\n",
        "    'MDVP:APQ': [0.02971], 'Shimmer:DDA': [0.06545], 'DFA': [0.73789],\n",
        "    'spread1': [-5.454504], 'spread2': [0.282866], 'D2': [2.000000], 'PPE': [0.100000]\n",
        "}, index=[0])\n",
        "\n",
        "print(\"\\nNew patient data for prediction:\")\n",
        "print(new_patient_data)\n",
        "\n",
        "# Align columns of new_patient_data with X_processed columns\n",
        "new_patient_data_aligned = new_patient_data.reindex(columns=X_processed.columns, fill_value=0)\n",
        "\n",
        "\n",
        "# Preprocess the new data using the loaded scaler and IQR bounds\n",
        "# Note: is_training=False, and provide the loaded scaler and IQR bounds\n",
        "new_patient_processed = preprocess_data(\n",
        "    new_patient_data_aligned,\n",
        "    scaler=loaded_scaler,\n",
        "    is_training=False,\n",
        "    train_iqr_bounds=loaded_train_iqr_bounds\n",
        ")\n",
        "\n",
        "# Make prediction\n",
        "new_prediction = loaded_model.predict(new_patient_processed)\n",
        "prediction_proba = loaded_model.predict_proba(new_patient_processed) # Get probabilities\n",
        "\n",
        "print(f\"\\nPredicted Outcome for new patient: {'Parkinsons Disease' if new_prediction[0] == 1 else 'No Parkinsons Disease'}\")\n",
        "print(f\"Prediction Probability (No Parkinsons Disease, Parkinsons Disease): {prediction_proba[0]}\")\n",
        "\n",
        "# Another example: a patient likely without Parkinson's disease (hypothetical normal values)\n",
        "new_patient_data_2 = pd.DataFrame({\n",
        "    'MDVP:Fo(Hz)': [150.0], 'MDVP:Fhi(Hz)': [200.0], 'MDVP:Flo(Hz)': [100.0],\n",
        "    'MDVP:Jitter(%)': [0.003], 'MDVP:Jitter(Abs)': [0.00002], 'MDVP:RAP': [0.00150],\n",
        "    'MDVP:PPQ': [0.00200], 'Jitter:DDP': [0.00450], 'MDVP:Shimmer': [0.01500],\n",
        "    'MDVP:Shimmer(dB)': [0.150], 'Shimmer:APQ3': [0.00700], 'Shimmer:APQ5': [0.00900],\n",
        "    'MDVP:APQ': [0.00800], 'Shimmer:DDA': [0.02100], 'DFA': [0.70000],\n",
        "    'spread1': [-4.000000], 'spread2': [0.200000], 'D2': [1.800000], 'PPE': [0.050000]\n",
        "}, index=[0])\n",
        "\n",
        "print(\"\\nNew patient data 2 for prediction:\")\n",
        "print(new_patient_data_2)\n",
        "\n",
        "# Align columns of new_patient_data_2 with X_processed columns\n",
        "new_patient_data_aligned_2 = new_patient_data_2.reindex(columns=X_processed.columns, fill_value=0)\n",
        "\n",
        "\n",
        "new_patient_processed_2 = preprocess_data(\n",
        "    new_patient_data_aligned_2,\n",
        "    scaler=loaded_scaler,\n",
        "    is_training=False,\n",
        "    train_iqr_bounds=loaded_train_iqr_bounds\n",
        ")\n",
        "\n",
        "new_prediction_2 = loaded_model.predict(new_patient_processed_2)\n",
        "prediction_proba_2 = loaded_model.predict_proba(new_patient_processed_2)\n",
        "\n",
        "print(f\"\\nPredicted Outcome for new patient 2: {'Parkinsons Disease' if new_prediction_2[0] == 1 else 'No Parkinsons Disease'}\")\n",
        "print(f\"Prediction Probability (No Parkinsons Disease, Parkinsons Disease): {prediction_proba_2[0]}\")"
      ]
    }
  ]
}