{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc6f813-bd9e-49dd-811b-be48791645c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "First 5 rows of the dataset:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "\n",
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "\n",
      "Applying preprocessing steps to training data...\n",
      "\n",
      "Missing values (after replacement of 0s in specific columns):\n",
      "Glucose          0\n",
      "BloodPressure    0\n",
      "SkinThickness    0\n",
      "Insulin          0\n",
      "BMI              0\n",
      "dtype: int64\n",
      "Outliers capped for all features.\n",
      "\n",
      "First 5 rows of scaled features (after outlier treatment):\n",
      "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
      "0     0.647150  0.865276      -0.019315       0.936123 -0.515442  0.181749   \n",
      "1    -0.848970 -1.205989      -0.531737       0.277236 -0.515442 -0.868783   \n",
      "2     1.245598  2.015979      -0.702545      -0.652184 -0.515442 -1.364034   \n",
      "3    -0.848970 -1.074480      -0.531737      -0.381651 -0.211679 -0.643669   \n",
      "4    -1.148194  0.503626      -2.752234       0.936123  1.371253  1.607471   \n",
      "\n",
      "   DiabetesPedigreeFunction       Age  \n",
      "0                  0.588927  1.445691  \n",
      "1                 -0.378101 -0.189304  \n",
      "2                  0.746595 -0.103252  \n",
      "3                 -1.022787 -1.049828  \n",
      "4                  2.596563 -0.017199  \n",
      "\n",
      "Original Training set size: 614 samples\n",
      "Original Testing set size: 154 samples\n",
      "Original Outcome distribution in training set:\n",
      "Outcome\n",
      "0    0.651466\n",
      "1    0.348534\n",
      "Name: proportion, dtype: float64\n",
      "Original Outcome distribution in testing set:\n",
      "Outcome\n",
      "0    0.649351\n",
      "1    0.350649\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Applying SMOTE to balance the training data...\n",
      "\n",
      "Resampled Training set size: 800 samples\n",
      "Resampled Outcome distribution in training set:\n",
      "Outcome\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Starting Enhanced Hyperparameter Tuning for SVM on resampled data (this might take a moment)...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "Best parameters found: {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Best cross-validation F1-weighted score on resampled data: 0.8181\n",
      "\n",
      "Best SVM model trained successfully using best parameters on resampled data.\n",
      "\n",
      "Model Accuracy on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment): 0.6688\n",
      "\n",
      "Classification Report on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77       100\n",
      "           1       0.55      0.31      0.40        54\n",
      "\n",
      "    accuracy                           0.67       154\n",
      "   macro avg       0.62      0.59      0.59       154\n",
      "weighted avg       0.65      0.67      0.64       154\n",
      "\n",
      "\n",
      "Confusion Matrix on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment):\n",
      "[[86 14]\n",
      " [37 17]]\n",
      "\n",
      "Model saved to diabetes_svm_model.joblib\n",
      "Scaler saved to diabetes_scaler.joblib\n",
      "Training means for imputation saved to diabetes_train_means.joblib\n",
      "Training IQR bounds for outlier treatment saved to diabetes_train_iqr_bounds.joblib\n",
      "\n",
      "--- Example: Loading saved model and predicting on new data ---\n",
      "Model, scaler, means, and IQR bounds loaded successfully.\n",
      "\n",
      "New patient data for prediction:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            2      180             80             30        0  35.5   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  \n",
      "0                       0.5   45  \n",
      "\n",
      "Predicted Outcome for new patient: Diabetic\n",
      "Prediction Probability (Non-Diabetic, Diabetic): [0.5 0.5]\n",
      "\n",
      "New patient data 2 for prediction:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            0       90             70             20       70  22.0   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  \n",
      "0                       0.2   25  \n",
      "\n",
      "Predicted Outcome for new patient 2: Non-Diabetic\n",
      "Prediction Probability (Non-Diabetic, Diabetic): [0.98053101 0.01946899]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE # Import SMOTE\n",
    "import joblib # For saving and loading models\n",
    "\n",
    "# --- 1. Load the dataset ---\n",
    "# The dataset 'diabetes.csv' is assumed to be available in the environment.\n",
    "try:\n",
    "    df = pd.read_csv('diabetes.csv')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(\"First 5 rows of the dataset:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDataset information:\")\n",
    "    df.info()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'diabetes.csv' not found. Please ensure the file is uploaded correctly.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Data Preprocessing ---\n",
    "\n",
    "# Identify features (X) and target (y)\n",
    "# 'Outcome' is typically the target variable (0 for no diabetes, 1 for diabetes)\n",
    "# All other columns are features.\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Define columns that might have 0s representing missing values\n",
    "cols_to_replace_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "# Function to apply preprocessing steps (missing value handling, outlier treatment, scaling)\n",
    "# This function will be used for both training and new data prediction\n",
    "def preprocess_data(data_df, scaler=None, is_training=True, train_means=None, train_iqr_bounds=None):\n",
    "    processed_df = data_df.copy()\n",
    "\n",
    "    # Handle missing values (0s replaced with mean)\n",
    "    # For new data, use means calculated from training data\n",
    "    if is_training:\n",
    "        for col in cols_to_replace_zero:\n",
    "            processed_df[col] = processed_df[col].replace(0, processed_df[col].mean())\n",
    "        # Store means for later use with new data\n",
    "        current_means = {col: processed_df[col].mean() for col in cols_to_replace_zero}\n",
    "    else:\n",
    "        if train_means is None:\n",
    "            raise ValueError(\"train_means must be provided for new data preprocessing.\")\n",
    "        for col in cols_to_replace_zero:\n",
    "            processed_df[col] = processed_df[col].replace(0, train_means[col])\n",
    "        current_means = train_means # No need to recalculate for new data\n",
    "\n",
    "    # Outlier Treatment (Capping using IQR method)\n",
    "    # For new data, use IQR bounds calculated from training data\n",
    "    current_iqr_bounds = {}\n",
    "    if is_training:\n",
    "        for column in processed_df.columns:\n",
    "            Q1 = processed_df[column].quantile(0.25)\n",
    "            Q3 = processed_df[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            processed_df[column] = processed_df[column].clip(lower=lower_bound, upper=upper_bound)\n",
    "            current_iqr_bounds[column] = {'lower': lower_bound, 'upper': upper_bound}\n",
    "    else:\n",
    "        if train_iqr_bounds is None:\n",
    "            raise ValueError(\"train_iqr_bounds must be provided for new data preprocessing.\")\n",
    "        for column in processed_df.columns:\n",
    "            lower_bound = train_iqr_bounds[column]['lower']\n",
    "            upper_bound = train_iqr_bounds[column]['upper']\n",
    "            processed_df[column] = processed_df[column].clip(lower=lower_bound, upper=upper_bound)\n",
    "        current_iqr_bounds = train_iqr_bounds # No need to recalculate for new data\n",
    "\n",
    "    # Feature Scaling\n",
    "    if is_training:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(processed_df)\n",
    "    else:\n",
    "        if scaler is None:\n",
    "            raise ValueError(\"Scaler must be provided for new data preprocessing.\")\n",
    "        scaled_data = scaler.transform(processed_df)\n",
    "\n",
    "    processed_df_scaled = pd.DataFrame(scaled_data, columns=processed_df.columns)\n",
    "\n",
    "    if is_training:\n",
    "        return processed_df_scaled, scaler, current_means, current_iqr_bounds\n",
    "    else:\n",
    "        return processed_df_scaled\n",
    "\n",
    "\n",
    "# Preprocess training data\n",
    "print(\"\\nApplying preprocessing steps to training data...\")\n",
    "X_processed, scaler, train_means, train_iqr_bounds = preprocess_data(X, is_training=True)\n",
    "\n",
    "print(\"\\nMissing values (after replacement of 0s in specific columns):\")\n",
    "print(X_processed[cols_to_replace_zero].isin([0]).sum()) # Should show 0 for these columns now\n",
    "\n",
    "print(\"Outliers capped for all features.\")\n",
    "\n",
    "print(\"\\nFirst 5 rows of scaled features (after outlier treatment):\")\n",
    "print(X_processed.head())\n",
    "\n",
    "# --- 3. Split the data into training and testing sets ---\n",
    "# We'll use 80% for training and 20% for testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nOriginal Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Original Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Original Outcome distribution in training set:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Original Outcome distribution in testing set:\\n{y_test.value_counts(normalize=True)}\")\n",
    "\n",
    "# --- 4. Apply SMOTE to the training data ---\n",
    "print(\"\\nApplying SMOTE to balance the training data...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"\\nResampled Training set size: {X_train_resampled.shape[0]} samples\")\n",
    "print(f\"Resampled Outcome distribution in training set:\\n{y_train_resampled.value_counts(normalize=True)}\")\n",
    "\n",
    "\n",
    "# --- 5. Train an SVM Classifier with Enhanced Hyperparameter Tuning on Resampled Data ---\n",
    "print(\"\\nStarting Enhanced Hyperparameter Tuning for SVM on resampled data (this might take a moment)...\")\n",
    "\n",
    "# Define an expanded parameter grid to search\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100, 1000],          # Regularization parameter: expanded range\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],      # Kernel coefficient for 'rbf': expanded range\n",
    "    'kernel': ['rbf']                            # Focusing on RBF kernel\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "# Set probability=True to enable predict_proba\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(random_state=42, class_weight='balanced', probability=True), # Added probability=True\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV to the RESAMPLED training data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation F1-weighted score on resampled data: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Get the best estimator (the SVM model with the best parameters)\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "print(\"\\nBest SVM model trained successfully using best parameters on resampled data.\")\n",
    "\n",
    "# --- 6. Evaluate the best model's performance on the ORIGINAL Test Set ---\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment): {accuracy:.4f}\")\n",
    "\n",
    "# Generate a classification report (precision, recall, f1-score)\n",
    "print(\"\\nClassification Report on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix on ORIGINAL Test Set (with best parameters, SMOTE, and Outlier Treatment):\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Interpretation of Confusion Matrix:\n",
    "# [[True Negatives (TN)  False Positives (FP)]\n",
    "#  [False Negatives (FN) True Positives (TP)]]\n",
    "# For diabetes prediction:\n",
    "# TN: Correctly predicted non-diabetic\n",
    "# FP: Incorrectly predicted diabetic (Type I error)\n",
    "# FN: Incorrectly predicted non-diabetic (Type II error, more critical in medical diagnosis)\n",
    "# TP: Correctly predicted diabetic\n",
    "\n",
    "# --- 7. Save the trained model and scaler ---\n",
    "model_filename = 'diabetes_svm_model.joblib'\n",
    "scaler_filename = 'diabetes_scaler.joblib'\n",
    "train_means_filename = 'diabetes_train_means.joblib'\n",
    "train_iqr_bounds_filename = 'diabetes_train_iqr_bounds.joblib'\n",
    "\n",
    "joblib.dump(best_svm_model, model_filename)\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "joblib.dump(train_means, train_means_filename)\n",
    "joblib.dump(train_iqr_bounds, train_iqr_bounds_filename)\n",
    "\n",
    "print(f\"\\nModel saved to {model_filename}\")\n",
    "print(f\"Scaler saved to {scaler_filename}\")\n",
    "print(f\"Training means for imputation saved to {train_means_filename}\")\n",
    "print(f\"Training IQR bounds for outlier treatment saved to {train_iqr_bounds_filename}\")\n",
    "\n",
    "\n",
    "# --- 8. Example: Load model and predict on new data ---\n",
    "print(\"\\n--- Example: Loading saved model and predicting on new data ---\")\n",
    "\n",
    "# Load the saved model, scaler, means, and IQR bounds\n",
    "loaded_model = joblib.load(model_filename)\n",
    "loaded_scaler = joblib.load(scaler_filename)\n",
    "loaded_train_means = joblib.load(train_means_filename)\n",
    "loaded_train_iqr_bounds = joblib.load(train_iqr_bounds_filename)\n",
    "\n",
    "print(\"Model, scaler, means, and IQR bounds loaded successfully.\")\n",
    "\n",
    "# Create some hypothetical new data for prediction\n",
    "# Ensure the new data has the same columns as the training data, in the same order\n",
    "# Example: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age\n",
    "new_patient_data = pd.DataFrame({\n",
    "    'Pregnancies': [2],\n",
    "    'Glucose': [180],\n",
    "    'BloodPressure': [80],\n",
    "    'SkinThickness': [30],\n",
    "    'Insulin': [0], # Example of a value that might be treated as missing\n",
    "    'BMI': [35.5],\n",
    "    'DiabetesPedigreeFunction': [0.5],\n",
    "    'Age': [45]\n",
    "})\n",
    "\n",
    "print(\"\\nNew patient data for prediction:\")\n",
    "print(new_patient_data)\n",
    "\n",
    "# Preprocess the new data using the loaded scaler, means, and IQR bounds\n",
    "# Note: is_training=False, and provide the loaded scaler, means, and IQR bounds\n",
    "new_patient_processed = preprocess_data(\n",
    "    new_patient_data,\n",
    "    scaler=loaded_scaler,\n",
    "    is_training=False,\n",
    "    train_means=loaded_train_means,\n",
    "    train_iqr_bounds=loaded_train_iqr_bounds\n",
    ")\n",
    "\n",
    "# Make prediction\n",
    "new_prediction = loaded_model.predict(new_patient_processed)\n",
    "prediction_proba = loaded_model.predict_proba(new_patient_processed) # Get probabilities\n",
    "\n",
    "print(f\"\\nPredicted Outcome for new patient: {'Diabetic' if new_prediction[0] == 1 else 'Non-Diabetic'}\")\n",
    "print(f\"Prediction Probability (Non-Diabetic, Diabetic): {prediction_proba[0]}\")\n",
    "\n",
    "# Another example: a patient likely non-diabetic\n",
    "new_patient_data_2 = pd.DataFrame({\n",
    "    'Pregnancies': [0],\n",
    "    'Glucose': [90],\n",
    "    'BloodPressure': [70],\n",
    "    'SkinThickness': [20],\n",
    "    'Insulin': [70],\n",
    "    'BMI': [22.0],\n",
    "    'DiabetesPedigreeFunction': [0.2],\n",
    "    'Age': [25]\n",
    "})\n",
    "\n",
    "print(\"\\nNew patient data 2 for prediction:\")\n",
    "print(new_patient_data_2)\n",
    "\n",
    "new_patient_processed_2 = preprocess_data(\n",
    "    new_patient_data_2,\n",
    "    scaler=loaded_scaler,\n",
    "    is_training=False,\n",
    "    train_means=loaded_train_means,\n",
    "    train_iqr_bounds=loaded_train_iqr_bounds\n",
    ")\n",
    "\n",
    "new_prediction_2 = loaded_model.predict(new_patient_processed_2)\n",
    "prediction_proba_2 = loaded_model.predict_proba(new_patient_processed_2)\n",
    "\n",
    "print(f\"\\nPredicted Outcome for new patient 2: {'Diabetic' if new_prediction_2[0] == 1 else 'Non-Diabetic'}\")\n",
    "print(f\"Prediction Probability (Non-Diabetic, Diabetic): {prediction_proba_2[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747cfa23-61d4-40e7-bfac-6dfc143a8db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
